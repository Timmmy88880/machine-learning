{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-5調整.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFFFbDA/rz/a72eREX4KFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timmmy88880/machine-learning/blob/cola/4_5%E8%AA%BF%E6%95%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_-N5QrWIouwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864fafc8-7c1b-400d-801e-61780374ba7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->japanize-matplotlib) (1.15.0)\n",
            "(569, 30)\n",
            "(512, 30)\n",
            "(57, 30)\n",
            "score: 0.9474  LogisticRegression\n",
            "score: 0.8947  SVC\n",
            "score: 0.9474  DecisionTreeClassifier\n",
            "score: 0.9298  RandomForestClassifier\n",
            "score: 0.9825  XGBClassifier\n",
            "SVC(random_state=123)\n",
            "score: 0.6316  gamma: 1\n",
            "score: 0.6316  gamma: 0.1\n",
            "score: 0.6316  gamma: 0.01\n",
            "score: 0.9474  gamma: 0.001\n",
            "score: 0.9474  gamma: 0.0001\n",
            "score: 0.9474  gamma: 1e-05\n",
            "score: 0.9474  C: 1\n",
            "score: 0.9298  C: 10\n",
            "score: 0.9298  C: 100\n",
            "score: 0.9298  C: 1000\n",
            "score: 0.9298  C: 10000\n",
            "平均スコア: 0.9141  個別スコア: [0.8889 0.9181 0.9353]\n",
            "平均スコア: 0.9453  個別スコア: [0.9357 0.9474 0.9529]  LogisticRegression\n",
            "平均スコア: 0.9141  個別スコア: [0.8889 0.9181 0.9353]  SVC\n",
            "平均スコア: 0.9062  個別スコア: [0.8713 0.9415 0.9059]  DecisionTreeClassifier\n",
            "平均スコア: 0.9629  個別スコア: [0.9649 0.9591 0.9647]  RandomForestClassifier\n",
            "平均スコア: 0.9590  個別スコア: [0.9591 0.9649 0.9529]  XGBClassifier\n",
            "SVC(C=1000, gamma=1e-05, random_state=123)\n",
            "スコア: 0.9825\n",
            "\n",
            "混同行列\n",
            "[[20  1]\n",
            " [ 0 36]]\n"
          ]
        }
      ],
      "source": [
        "#4.5 チューニング\n",
        "#共通事前処理\n",
        "# 日本語化ライブラリ導入\n",
        "!pip install japanize-matplotlib | tail -n 1\n",
        "# 共通事前処理\n",
        "\n",
        "# 余分なワーニングを非表示にする\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 必要ライブラリのimport\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# matplotlib日本語化対応\n",
        "import japanize_matplotlib\n",
        "\n",
        "# データフレーム表示用関数\n",
        "from IPython.display import display\n",
        "\n",
        "# 表示オプション調整\n",
        "# numpyの浮動小数点の表示精度\n",
        "np.set_printoptions(suppress=True, precision=4)\n",
        "# pandasでの浮動小数点の表示精度\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "# データフレームですべての項目を表示\n",
        "pd.set_option(\"display.max_columns\",None)\n",
        "# グラフのデフォルトフォント指定\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "# 乱数の種\n",
        "random_seed = 123\n",
        "#サンプルデータの読み込み\n",
        "# サンプルデータの読み込み\n",
        "# (乳がん疾患データ)\n",
        "\n",
        "# データのロード\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# 入力データ: x (30次元)\n",
        "# 正解データ: y\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "# サンプルデータの分割\n",
        "\n",
        "# データ分割のパラメータ\n",
        "test_size = 0.1\n",
        "\n",
        "# データ分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
        "    test_size=test_size, random_state=random_seed,\n",
        "    stratify=y)\n",
        "\n",
        "# 分割後サイズ確認\n",
        "print(x.shape)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "#4.5.1 アルゴリズムの選択\n",
        "# 複数アルゴリズムで精度を比較\n",
        "# 結果が同じになるようrandom_stateは同一にする\n",
        "\n",
        "# 線形回帰\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "algorithm1 = LogisticRegression(random_state=random_seed)\n",
        "\n",
        "# サポートベクターマシン(カーネル)\n",
        "from sklearn.svm import SVC\n",
        "algorithm2 = SVC(kernel='rbf', random_state=random_seed)\n",
        "\n",
        "# 決定木\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "algorithm3 = DecisionTreeClassifier(random_state=random_seed)\n",
        "\n",
        "# ランダムフォレスト\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "algorithm4 = RandomForestClassifier(random_state=random_seed)\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "algorithm5 = XGBClassifier(random_state=random_seed)\n",
        "\n",
        "# アルゴリズムのリスト作成\n",
        "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, \n",
        "    algorithm5]\n",
        "# 複数アルゴリズムで精度比較\n",
        "for algorithm in algorithms:\n",
        "    \n",
        "    # 訓練データで学習\n",
        "    algorithm.fit(x_train, y_train)\n",
        "    \n",
        "    # 検証データで精度測定\n",
        "    score = algorithm.score(x_test, y_test)\n",
        "    \n",
        "    # アルゴリズム名取得\n",
        "    name = algorithm.__class__.__name__\n",
        "\n",
        "    # 精度とアルゴリズム名表示\n",
        "    print(f'score: {score:.4f}  {name}')\n",
        "#4.5.2 ハイパーパラメータの最適化\n",
        "# デフォルトパラメータの確認\n",
        "algorithm = SVC(kernel='rbf', random_state=random_seed)\n",
        "print(algorithm)\n",
        "# gammaの最適化\n",
        "algorithm = SVC(kernel='rbf', random_state=random_seed)\n",
        "gammas = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
        "\n",
        "for gamma in gammas:\n",
        "    algorithm.gamma = gamma\n",
        "    algorithm.fit(x_train, y_train)\n",
        "    score = algorithm.score(x_test, y_test)\n",
        "    print(f'score: {score:.4f}  gamma: {gamma}')\n",
        "# Cの最適化\n",
        "# gammaは先ほど調べた最適値 0.001を採用\n",
        "\n",
        "Cs = [1,  10,  100, 1000, 10000]\n",
        "for C in Cs:\n",
        "    algorithm = SVC(kernel='rbf', \n",
        "        gamma=0.001, C=C,\n",
        "        random_state=random_seed)\n",
        "    algorithm.fit(x_train, y_train)\n",
        "    score = algorithm.score(x_test, y_test)\n",
        "    print(f'score: {score:.4f}  C: {C}')\n",
        "#4.5.3 交差検定法\n",
        "# 特定のアルゴリズムに対して交差検定を実施\n",
        "\n",
        "# アルゴリズムの定義\n",
        "algorithm = SVC(kernel='rbf',random_state=random_seed,\n",
        "    gamma=0.001, C=1)\n",
        "\n",
        "# 分割時に正解データの分布が偏らないようにStratifiedKFoldを利用\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
        "\n",
        "# 交差検定の実施 (分割数=3)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(algorithm , x_train, y_train, \n",
        "    cv=stratifiedkfold)\n",
        "\n",
        "# 平均値の計算\n",
        "mean = scores.mean()\n",
        "\n",
        "# 結果表示\n",
        "print(f'平均スコア: {mean:.4f}  個別スコア: {scores}')\n",
        "# 候補アルゴリズムのリスト作成\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "algorithm1 = LogisticRegression(random_state=random_seed)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "algorithm2 = SVC(kernel='rbf',random_state=random_seed,\n",
        "    gamma=0.001, C=1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "algorithm3 = DecisionTreeClassifier(random_state=random_seed)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "algorithm4 = RandomForestClassifier(random_state=random_seed)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "algorithm5 = XGBClassifier(random_state=random_seed)\n",
        "\n",
        "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, \n",
        "    algorithm5]\n",
        "# 複数アルゴリズムで精度を比較\n",
        "\n",
        "# 分割時に正解データの分布が偏らないようにStratifiedKFoldを利用\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "for algorithm in algorithms:\n",
        "    # 交差検定法の実行\n",
        "    scores = cross_val_score(algorithm , x_train, y_train, \n",
        "        cv=stratifiedkfold)\n",
        "    score = scores.mean()\n",
        "    name = algorithm.__class__.__name__\n",
        "    print(f'平均スコア: {score:.4f}  個別スコア: {scores}  {name}')\n",
        "#4.5.4 グリッドサーチ\n",
        "# グリッドサーチを交差検定を組み合わせて最適なパラメータを探索\n",
        "params = {\n",
        "      'C':[1, 10, 100, 1000, 10000],\n",
        "      'gamma':[1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
        "}\n",
        "algorithm = SVC(random_state=random_seed)\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "gs = GridSearchCV(algorithm, params, cv=stratifiedkfold)\n",
        "gs.fit(x_train, y_train)\n",
        "\n",
        "# ベストのモデルを取得し検証データを分類\n",
        "best = gs.best_estimator_\n",
        "best_pred = best.predict(x_test)\n",
        "print(best)\n",
        "# 精度の取得\n",
        "score = best.score(x_test, y_test)\n",
        "print(f'スコア: {score:.4f}')\n",
        "\n",
        "# 混同行列を出力\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print()\n",
        "print('混同行列')\n",
        "print(confusion_matrix(y_test, best_pred))"
      ]
    }
  ]
}